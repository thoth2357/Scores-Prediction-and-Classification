{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "from EDA import Preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read datasets\n",
    "import pandas as pd\n",
    "\n",
    "df_mat = pd.read_csv('/home/pirate/Documents/machine_learning/score_prediction/student/student-mat.csv',sep=';')\n",
    "df_por = pd.read_csv('/home/pirate/Documents/machine_learning/score_prediction/student/student-por.csv',sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling duplicates found in datasets\n",
    "df_merged=df_mat.append(df_por, ignore_index=True)\n",
    "no_of_duplicates = df_merged.duplicated([\"school\",\"sex\",\"age\",\"address\",\"famsize\",\"Pstatus\",\"Medu\",\"Fedu\",\"Mjob\",\"Fjob\",\"reason\",\"nursery\",\"internet\"]).sum()\n",
    "print(f'---> We have {no_of_duplicates} found in our two datasets\\n')\n",
    "\n",
    "print('---> Merging datasets and removing duplicates\\n')\n",
    "df_merged.drop_duplicates(subset=[\"school\",\"sex\",\"age\",\"address\",\"famsize\",\"Pstatus\",\"Medu\",\"Fedu\",\"Mjob\",\"Fjob\",\"reason\",\"nursery\",\"internet\"],\n",
    "                 keep = 'first', inplace = True)\n",
    "\n",
    "print(f'---> After merging and removing duplicates we have {len(df_merged)} unique rows')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> No Missing Value was found data is clean and ready to use\n",
      "---> Showing descriptive statistics of the dataset\n",
      "               age        Medu        Fedu  traveltime   studytime  \\\n",
      "count   662.000000  662.000000  662.000000  662.000000  662.000000   \n",
      "mean     16.812689    2.492447    2.293051    1.564955    1.927492   \n",
      "std       1.269194    1.130958    1.094027    0.742799    0.827405   \n",
      "min      15.000000    0.000000    0.000000    1.000000    1.000000   \n",
      "25%      16.000000    2.000000    1.000000    1.000000    1.000000   \n",
      "50%      17.000000    2.000000    2.000000    1.000000    2.000000   \n",
      "75%      18.000000    4.000000    3.000000    2.000000    2.000000   \n",
      "max      22.000000    4.000000    4.000000    4.000000    4.000000   \n",
      "median   17.000000    2.000000    2.000000    1.000000    2.000000   \n",
      "skew      0.422084   -0.006391    0.233855    1.253308    0.698354   \n",
      "kurt     -0.031293   -1.254753   -1.088070    1.164596    0.039527   \n",
      "\n",
      "          failures      famrel    freetime       goout        Dalc  \\\n",
      "count   662.000000  662.000000  662.000000  662.000000  662.000000   \n",
      "mean      0.332326    3.938066    3.184290    3.172205    1.504532   \n",
      "std       0.716024    0.941930    1.060583    1.161907    0.926567   \n",
      "min       0.000000    1.000000    1.000000    1.000000    1.000000   \n",
      "25%       0.000000    4.000000    3.000000    2.000000    1.000000   \n",
      "50%       0.000000    4.000000    3.000000    3.000000    1.000000   \n",
      "75%       0.000000    5.000000    4.000000    4.000000    2.000000   \n",
      "max       3.000000    5.000000    5.000000    5.000000    5.000000   \n",
      "median    0.000000    4.000000    3.000000    3.000000    1.000000   \n",
      "skew      2.363761   -1.107387   -0.189793   -0.002315    2.121290   \n",
      "kurt      5.113053    1.416695   -0.431887   -0.833895    4.231877   \n",
      "\n",
      "              Walc      health    absences          G1          G2          G3  \n",
      "count   662.000000  662.000000  662.000000  662.000000  662.000000  662.000000  \n",
      "mean      2.282477    3.531722    4.930514   10.728097   10.708459   10.725076  \n",
      "std       1.290121    1.434835    6.858060    3.082098    3.529588    4.106738  \n",
      "min       1.000000    1.000000    0.000000    3.000000    0.000000    0.000000  \n",
      "25%       1.000000    2.000000    0.000000    8.000000    9.000000    9.000000  \n",
      "50%       2.000000    4.000000    3.000000   10.000000   11.000000   11.000000  \n",
      "75%       3.000000    5.000000    8.000000   13.000000   13.000000   13.000000  \n",
      "max       5.000000    5.000000   75.000000   19.000000   19.000000   20.000000  \n",
      "median    2.000000    4.000000    3.000000   10.000000   11.000000   11.000000  \n",
      "skew      0.624529   -0.492264    3.843050    0.303780   -0.415990   -0.805366  \n",
      "kurt     -0.800780   -1.102938   26.207011   -0.444839    1.008060    1.109024  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'Medu',\n",
       " 'Fedu',\n",
       " 'traveltime',\n",
       " 'studytime',\n",
       " 'failures',\n",
       " 'famrel',\n",
       " 'freetime',\n",
       " 'goout',\n",
       " 'Dalc',\n",
       " 'Walc',\n",
       " 'health',\n",
       " 'absences',\n",
       " 'G1',\n",
       " 'G2',\n",
       " 'G3']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                    # PERFORMING EDA\n",
    "preprocessor = Preprocessing(df_merged)\n",
    "#check for missing values\n",
    "df_missing_value_pass = preprocessor.check_missing_value()\n",
    "\n",
    "#check dataset descriptives\n",
    "preprocessor.descriptives(df_missing_value_pass)\n",
    "\n",
    "#perform data exploration\n",
    "##separting dataset into categorical and continuous columns\n",
    "numerical_columns_selector = selector(dtype_exclude=object)\n",
    "categorical_columns_selector = selector(dtype_include=object)\n",
    "continous_columns = numerical_columns_selector(df_missing_value_pass)\n",
    "categorical_columns = categorical_columns_selector(df_missing_value_pass)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9013e23377c4df86dc09c341e3e8e9dd81c02c4de203807e1a62a3a9bc38c81"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
